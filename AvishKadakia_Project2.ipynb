{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "indian-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard imports\n",
    "import numpy as np \n",
    "\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "historical-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-finding",
   "metadata": {},
   "source": [
    "# Logistic Regression Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "little-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log, dot, e\n",
    "from numpy.random import rand\n",
    "batch_size = 1000\n",
    "epochs = 50\n",
    "height = 50\n",
    "width = 50\n",
    "class LogisticRegression:\n",
    "    def __init__(self,input_size, lr=0.05):\n",
    "        self.weights = rand(input_size)\n",
    "        self.lr = lr\n",
    "    def sigmoid(self, z): return 1 / (1 + e**(-z))\n",
    "    \n",
    "    def fit(self, X, y): \n",
    "        N = len(X)\n",
    "        # Predicting with sigmoid function\n",
    "        y_hat = self.sigmoid(dot(X, self.weights))\n",
    "        # Updating Weights using Gradient Descent\n",
    "        self.weights -= self.lr * (dot(X.T,  y_hat - y) / N  )\n",
    "\n",
    "    \n",
    "    def predict(self, X):        \n",
    "        # Predicting with sigmoid function\n",
    "        z = dot(X, self.weights)\n",
    "        # Returning binary result\n",
    "        return [1 if i > 0.5 else 0 for i in self.sigmoid(z)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-holocaust",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "french-edmonton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: \n",
      "Found 23000 images belonging to 2 classes.\n",
      "Training model:\n",
      "Epoch 0/50 Training Accuracy: 50.026086956521745\n",
      "Epoch 1/50 Training Accuracy: 50.81739130434782\n",
      "Epoch 2/50 Training Accuracy: 52.73478260869565\n",
      "Epoch 3/50 Training Accuracy: 50.88260869565217\n",
      "Epoch 4/50 Training Accuracy: 50.778260869565216\n",
      "Epoch 5/50 Training Accuracy: 50.4304347826087\n",
      "Epoch 6/50 Training Accuracy: 50.73913043478261\n",
      "Epoch 7/50 Training Accuracy: 50.57391304347827\n",
      "Epoch 8/50 Training Accuracy: 51.00869565217392\n",
      "Epoch 9/50 Training Accuracy: 50.31739130434784\n",
      "Epoch 10/50 Training Accuracy: 51.30869565217391\n",
      "Epoch 11/50 Training Accuracy: 51.09565217391305\n",
      "Epoch 12/50 Training Accuracy: 50.0695652173913\n",
      "Epoch 13/50 Training Accuracy: 50.58695652173913\n",
      "Epoch 14/50 Training Accuracy: 50.36956521739132\n",
      "Epoch 15/50 Training Accuracy: 50.63913043478261\n",
      "Epoch 16/50 Training Accuracy: 50.786956521739135\n",
      "Epoch 17/50 Training Accuracy: 50.473913043478255\n",
      "Epoch 18/50 Training Accuracy: 50.98695652173914\n",
      "Epoch 19/50 Training Accuracy: 51.221739130434784\n",
      "Epoch 20/50 Training Accuracy: 51.03478260869565\n",
      "Epoch 21/50 Training Accuracy: 51.22173913043477\n",
      "Epoch 22/50 Training Accuracy: 51.260869565217384\n",
      "Epoch 23/50 Training Accuracy: 50.64347826086957\n",
      "Epoch 24/50 Training Accuracy: 50.982608695652175\n",
      "Epoch 25/50 Training Accuracy: 51.02608695652173\n",
      "Epoch 26/50 Training Accuracy: 50.765217391304354\n",
      "Epoch 27/50 Training Accuracy: 51.10869565217392\n",
      "Epoch 28/50 Training Accuracy: 50.52173913043478\n",
      "Epoch 29/50 Training Accuracy: 50.786956521739135\n",
      "Epoch 30/50 Training Accuracy: 50.92608695652173\n",
      "Epoch 31/50 Training Accuracy: 50.978260869565204\n",
      "Epoch 32/50 Training Accuracy: 51.10869565217392\n",
      "Epoch 33/50 Training Accuracy: 50.99130434782608\n",
      "Epoch 34/50 Training Accuracy: 50.83478260869565\n",
      "Epoch 35/50 Training Accuracy: 51.15652173913045\n",
      "Epoch 36/50 Training Accuracy: 50.69565217391304\n",
      "Epoch 37/50 Training Accuracy: 50.534782608695636\n",
      "Epoch 38/50 Training Accuracy: 50.87826086956523\n",
      "Epoch 39/50 Training Accuracy: 51.265217391304354\n",
      "Epoch 40/50 Training Accuracy: 51.23478260869565\n",
      "Epoch 41/50 Training Accuracy: 51.75652173913045\n",
      "Epoch 42/50 Training Accuracy: 51.31739130434782\n",
      "Epoch 43/50 Training Accuracy: 51.060869565217395\n",
      "Epoch 44/50 Training Accuracy: 50.77391304347827\n",
      "Epoch 45/50 Training Accuracy: 50.35652173913042\n",
      "Epoch 46/50 Training Accuracy: 51.35217391304349\n",
      "Epoch 47/50 Training Accuracy: 50.76956521739131\n",
      "Epoch 48/50 Training Accuracy: 50.947826086956525\n",
      "Epoch 49/50 Training Accuracy: 50.94347826086958\n",
      "Training completed in 2007.4684281349182 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading training data: \")\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'Dataset/train',\n",
    "        target_size=(height,width),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        shuffle=True,\n",
    "        class_mode='binary')\n",
    "batch_x,batch_y = train_generator.next()\n",
    "batch_x = batch_x.reshape(batch_size,-1)\n",
    "lr = LogisticRegression(batch_x.shape[1])\n",
    "start_time = time.time()\n",
    "print(\"Training model:\")\n",
    "for i in range(epochs):\n",
    "    accuracy = 0\n",
    "    for j in range(int(train_generator.samples / batch_size)):\n",
    "        #print(f\"Training Epoch: {i} Batch: {j}\")\n",
    "        lr.fit(batch_x,batch_y)\n",
    "        batch_x,batch_y = train_generator.next()\n",
    "        batch_x = batch_x.reshape(batch_size,-1)\n",
    "        accuracy += accuracy_score(batch_y,lr.predict(batch_x))\n",
    "    print(f\"Epoch {i}/{epochs} Training Accuracy: {(accuracy / int(train_generator.samples / batch_size)) * 100}\")\n",
    "print(f\"Training completed in {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-montana",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "mathematical-improvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data: \n",
      "Found 12500 images belonging to 2 classes.\n",
      "Testing model:\n",
      "Testing accuracy: 50.29166666666666\n",
      "Testing completed in 801.0907106399536 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Loading test data: \")\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'Dataset/test',\n",
    "        target_size=(height,width),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        shuffle=True,\n",
    "        class_mode='binary')\n",
    "test_x,test_y = test_generator.next()\n",
    "test_x = test_x.reshape(batch_size,-1)  \n",
    "    \n",
    "print(\"Testing model:\") \n",
    "test_accuracy = 0\n",
    "for j in range(int(test_generator.samples / batch_size)):\n",
    "    #print(f\"Testing Batch: {j}\")\n",
    "    test_accuracy += accuracy_score(test_y,lr.predict(test_x))\n",
    "    test_x,test_y = test_generator.next()\n",
    "    test_x = test_x.reshape(batch_size,-1)\n",
    "        \n",
    "print(f\"Testing accuracy: {(test_accuracy / int(test_generator.samples / batch_size)) * 100}\")\n",
    "print(f\"Testing completed in {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-offer",
   "metadata": {},
   "source": [
    "# Pytorch Api Classification Model (NN - CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "patient-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "batch_size = 100\n",
    "epochs = 150\n",
    "height = 50\n",
    "width = 50\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(height * width, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "moved-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-retirement",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "married-healing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: \n",
      "Found 23000 images belonging to 2 classes.\n",
      "Training Model: \n",
      "Epoch 0/150 Training Accuracy: 55.1695652173913\n",
      "Epoch 1/150 Training Accuracy: 57.38260869565217\n",
      "Epoch 2/150 Training Accuracy: 58.47826086956522\n",
      "Epoch 3/150 Training Accuracy: 59.19130434782609\n",
      "Epoch 4/150 Training Accuracy: 60.06086956521739\n",
      "Epoch 5/150 Training Accuracy: 60.61304347826087\n",
      "Epoch 6/150 Training Accuracy: 61.108695652173914\n",
      "Epoch 7/150 Training Accuracy: 61.4\n",
      "Epoch 8/150 Training Accuracy: 61.7304347826087\n",
      "Epoch 9/150 Training Accuracy: 62.073913043478264\n",
      "Epoch 10/150 Training Accuracy: 62.391304347826086\n",
      "Epoch 11/150 Training Accuracy: 62.90869565217391\n",
      "Epoch 12/150 Training Accuracy: 62.73913043478261\n",
      "Epoch 13/150 Training Accuracy: 63.504347826086956\n",
      "Epoch 14/150 Training Accuracy: 63.54347826086956\n",
      "Epoch 15/150 Training Accuracy: 64.11739130434782\n",
      "Epoch 16/150 Training Accuracy: 64.08695652173913\n",
      "Epoch 17/150 Training Accuracy: 64.65217391304348\n",
      "Epoch 18/150 Training Accuracy: 64.68695652173913\n",
      "Epoch 19/150 Training Accuracy: 65.2304347826087\n",
      "Epoch 20/150 Training Accuracy: 65.38695652173914\n",
      "Epoch 21/150 Training Accuracy: 65.68695652173913\n",
      "Epoch 22/150 Training Accuracy: 66.35217391304347\n",
      "Epoch 23/150 Training Accuracy: 66.60434782608695\n",
      "Epoch 24/150 Training Accuracy: 66.82608695652173\n",
      "Epoch 25/150 Training Accuracy: 67.1\n",
      "Epoch 26/150 Training Accuracy: 67.34347826086956\n",
      "Epoch 27/150 Training Accuracy: 68.13913043478261\n",
      "Epoch 28/150 Training Accuracy: 68.48260869565217\n",
      "Epoch 29/150 Training Accuracy: 68.43478260869566\n",
      "Epoch 30/150 Training Accuracy: 69.00869565217391\n",
      "Epoch 31/150 Training Accuracy: 69.55652173913043\n",
      "Epoch 32/150 Training Accuracy: 69.6304347826087\n",
      "Epoch 33/150 Training Accuracy: 69.80434782608695\n",
      "Epoch 34/150 Training Accuracy: 70.76086956521739\n",
      "Epoch 35/150 Training Accuracy: 70.45217391304348\n",
      "Epoch 36/150 Training Accuracy: 71.13913043478261\n",
      "Epoch 37/150 Training Accuracy: 71.1\n",
      "Epoch 38/150 Training Accuracy: 71.56521739130434\n",
      "Epoch 39/150 Training Accuracy: 72.07826086956521\n",
      "Epoch 40/150 Training Accuracy: 73.08260869565217\n",
      "Epoch 41/150 Training Accuracy: 73.44347826086957\n",
      "Epoch 42/150 Training Accuracy: 73.86086956521739\n",
      "Epoch 43/150 Training Accuracy: 73.20869565217392\n",
      "Epoch 44/150 Training Accuracy: 73.64347826086957\n",
      "Epoch 45/150 Training Accuracy: 74.99565217391304\n",
      "Epoch 46/150 Training Accuracy: 75.81304347826087\n",
      "Epoch 47/150 Training Accuracy: 75.9\n",
      "Epoch 48/150 Training Accuracy: 75.64347826086957\n",
      "Epoch 49/150 Training Accuracy: 77.13913043478261\n",
      "Epoch 50/150 Training Accuracy: 76.63913043478261\n",
      "Epoch 51/150 Training Accuracy: 77.22173913043478\n",
      "Epoch 52/150 Training Accuracy: 78.70869565217392\n",
      "Epoch 53/150 Training Accuracy: 78.4608695652174\n",
      "Epoch 54/150 Training Accuracy: 79.4608695652174\n",
      "Epoch 55/150 Training Accuracy: 78.11304347826086\n",
      "Epoch 56/150 Training Accuracy: 78.16956521739131\n",
      "Epoch 57/150 Training Accuracy: 80.13478260869566\n",
      "Epoch 58/150 Training Accuracy: 79.99565217391304\n",
      "Epoch 59/150 Training Accuracy: 80.12173913043478\n",
      "Epoch 60/150 Training Accuracy: 80.62173913043478\n",
      "Epoch 61/150 Training Accuracy: 81.20869565217392\n",
      "Epoch 62/150 Training Accuracy: 80.75652173913043\n",
      "Epoch 63/150 Training Accuracy: 81.75217391304348\n",
      "Epoch 64/150 Training Accuracy: 82.72173913043478\n",
      "Epoch 65/150 Training Accuracy: 82.78695652173913\n",
      "Epoch 66/150 Training Accuracy: 83.56086956521739\n",
      "Epoch 67/150 Training Accuracy: 82.94347826086957\n",
      "Epoch 68/150 Training Accuracy: 83.64782608695653\n",
      "Epoch 69/150 Training Accuracy: 82.96521739130435\n",
      "Epoch 70/150 Training Accuracy: 84.67391304347827\n",
      "Epoch 71/150 Training Accuracy: 83.33043478260869\n",
      "Epoch 72/150 Training Accuracy: 86.30869565217391\n",
      "Epoch 73/150 Training Accuracy: 85.42173913043479\n",
      "Epoch 74/150 Training Accuracy: 85.40869565217392\n",
      "Epoch 75/150 Training Accuracy: 85.94782608695652\n",
      "Epoch 76/150 Training Accuracy: 85.4695652173913\n",
      "Epoch 77/150 Training Accuracy: 85.77826086956522\n",
      "Epoch 78/150 Training Accuracy: 87.32173913043478\n",
      "Epoch 79/150 Training Accuracy: 85.49565217391304\n",
      "Epoch 80/150 Training Accuracy: 87.09565217391304\n",
      "Epoch 81/150 Training Accuracy: 87.74782608695652\n",
      "Epoch 82/150 Training Accuracy: 87.07391304347826\n",
      "Epoch 83/150 Training Accuracy: 89.75217391304348\n",
      "Epoch 84/150 Training Accuracy: 88.57391304347826\n",
      "Epoch 85/150 Training Accuracy: 88.71304347826087\n",
      "Epoch 86/150 Training Accuracy: 89.68260869565218\n",
      "Epoch 87/150 Training Accuracy: 90.20434782608696\n",
      "Epoch 88/150 Training Accuracy: 88.9695652173913\n",
      "Epoch 89/150 Training Accuracy: 89.72173913043478\n",
      "Epoch 90/150 Training Accuracy: 90.65217391304348\n",
      "Epoch 91/150 Training Accuracy: 90.91304347826087\n",
      "Epoch 92/150 Training Accuracy: 90.64347826086957\n",
      "Epoch 93/150 Training Accuracy: 91.69565217391305\n",
      "Epoch 94/150 Training Accuracy: 91.59565217391304\n",
      "Epoch 95/150 Training Accuracy: 91.81739130434782\n",
      "Epoch 96/150 Training Accuracy: 92.52173913043478\n",
      "Epoch 97/150 Training Accuracy: 91.92173913043479\n",
      "Epoch 98/150 Training Accuracy: 94.65217391304348\n",
      "Epoch 99/150 Training Accuracy: 93.67826086956522\n",
      "Epoch 100/150 Training Accuracy: 94.25217391304348\n",
      "Epoch 101/150 Training Accuracy: 92.90434782608696\n",
      "Epoch 102/150 Training Accuracy: 94.5391304347826\n",
      "Epoch 103/150 Training Accuracy: 93.58260869565217\n",
      "Epoch 104/150 Training Accuracy: 93.0695652173913\n",
      "Epoch 105/150 Training Accuracy: 94.13478260869566\n",
      "Epoch 106/150 Training Accuracy: 94.2\n",
      "Epoch 107/150 Training Accuracy: 94.82608695652173\n",
      "Epoch 108/150 Training Accuracy: 95.32608695652173\n",
      "Epoch 109/150 Training Accuracy: 95.69130434782609\n",
      "Epoch 110/150 Training Accuracy: 93.86086956521739\n",
      "Epoch 111/150 Training Accuracy: 92.97826086956522\n",
      "Epoch 112/150 Training Accuracy: 96.30434782608695\n",
      "Epoch 113/150 Training Accuracy: 95.8391304347826\n",
      "Epoch 114/150 Training Accuracy: 96.75652173913043\n",
      "Epoch 115/150 Training Accuracy: 94.77826086956522\n",
      "Epoch 116/150 Training Accuracy: 95.9\n",
      "Epoch 117/150 Training Accuracy: 97.04782608695652\n",
      "Epoch 118/150 Training Accuracy: 97.04347826086956\n",
      "Epoch 119/150 Training Accuracy: 97.54782608695652\n",
      "Epoch 120/150 Training Accuracy: 98.2304347826087\n",
      "Epoch 121/150 Training Accuracy: 97.04782608695652\n",
      "Epoch 122/150 Training Accuracy: 96.28260869565217\n",
      "Epoch 123/150 Training Accuracy: 98.38695652173914\n",
      "Epoch 124/150 Training Accuracy: 97.79565217391304\n",
      "Epoch 125/150 Training Accuracy: 93.15652173913044\n",
      "Epoch 126/150 Training Accuracy: 94.82173913043478\n",
      "Epoch 127/150 Training Accuracy: 97.64782608695653\n",
      "Epoch 128/150 Training Accuracy: 96.4\n",
      "Epoch 129/150 Training Accuracy: 97.48695652173913\n",
      "Epoch 130/150 Training Accuracy: 93.23913043478261\n",
      "Epoch 131/150 Training Accuracy: 97.47826086956522\n",
      "Epoch 132/150 Training Accuracy: 98.83478260869565\n",
      "Epoch 133/150 Training Accuracy: 97.34782608695652\n",
      "Epoch 134/150 Training Accuracy: 98.6608695652174\n",
      "Epoch 135/150 Training Accuracy: 99.14347826086957\n",
      "Epoch 136/150 Training Accuracy: 99.23478260869565\n",
      "Epoch 137/150 Training Accuracy: 99.37826086956522\n",
      "Epoch 138/150 Training Accuracy: 99.52173913043478\n",
      "Epoch 139/150 Training Accuracy: 99.59565217391304\n",
      "Epoch 140/150 Training Accuracy: 99.70434782608696\n",
      "Epoch 141/150 Training Accuracy: 99.58260869565217\n",
      "Epoch 142/150 Training Accuracy: 99.7695652173913\n",
      "Epoch 143/150 Training Accuracy: 99.81739130434782\n",
      "Epoch 144/150 Training Accuracy: 99.80434782608695\n",
      "Epoch 145/150 Training Accuracy: 99.91739130434783\n",
      "Epoch 146/150 Training Accuracy: 99.88695652173914\n",
      "Epoch 147/150 Training Accuracy: 99.89565217391305\n",
      "Epoch 148/150 Training Accuracy: 99.94347826086957\n",
      "Epoch 149/150 Training Accuracy: 99.93478260869566\n",
      "Training competed in 9431.820527076721\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading training data: \")\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'Dataset/train',\n",
    "        target_size=(height,width),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        shuffle=True,\n",
    "        class_mode='binary')\n",
    "batch_x,batch_y = train_generator.next()\n",
    "batch_x = batch_x.reshape(batch_size,-1)\n",
    "#batch_y = tf.keras.utils.to_categorical(batch_y, 2)\n",
    "inputs, labels = batch_x,batch_y\n",
    "def acc(y_true,y_pred):\n",
    "    count = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if(y_true[i] == np.argmax(y_pred[i])):\n",
    "            count +=1\n",
    "    return count\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Training Model: \")\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    accuracy = 0\n",
    "    for j in range(int(train_generator.samples / batch_size)):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.from_numpy(inputs))\n",
    "        outputs_temp = outputs\n",
    "        loss = criterion(outputs, torch.from_numpy(labels).long() )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy = accuracy + acc(batch_y,outputs_temp.detach().numpy())\n",
    "        #print(f\"Training Epoch: {i} Batch: {j}\")\n",
    "        batch_x,batch_y = train_generator.next()\n",
    "        batch_x = batch_x.reshape(batch_size,-1)\n",
    "        inputs, labels = batch_x,batch_y\n",
    "    print(f\"Epoch {epoch}/{epochs} Training Accuracy: {accuracy / int(train_generator.samples / batch_size)}\")\n",
    "print(f'Training competed in {time.time() - start_time}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-plumbing",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "recent-fundamental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data: \n",
      "Found 12500 images belonging to 2 classes.\n",
      "Testing model:\n",
      "Testing accuracy: 99.952\n",
      "Testing competed in 258.94079184532166\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test data: \")\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'Dataset/test',\n",
    "        target_size=(height,width),\n",
    "        batch_size=batch_size,\n",
    "        color_mode=\"grayscale\",\n",
    "        shuffle=True,\n",
    "        class_mode='binary')\n",
    "test_x,test_y = test_generator.next()\n",
    "test_x = test_x.reshape(batch_size,-1)  \n",
    "start_time = time.time()\n",
    "print(\"Testing model:\") \n",
    "test_accuracy = 0\n",
    "for j in range(int(test_generator.samples / batch_size)):\n",
    "    #print(f\"Testing Batch: {j}\")\n",
    "    optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(torch.from_numpy(test_x))\n",
    "    test_accuracy = test_accuracy + acc(test_y,outputs.detach().numpy())\n",
    "    test_x,test_y = test_generator.next()\n",
    "    test_x = test_x.reshape(batch_size,-1)\n",
    "        \n",
    "print(f\"Testing accuracy: {test_accuracy / int(test_generator.samples / batch_size)}\")\n",
    "print(f'Testing competed in {time.time() - start_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
